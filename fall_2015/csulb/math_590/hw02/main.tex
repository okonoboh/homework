\documentclass[9pt]{article}

\usepackage{amssymb}
\usepackage{amsmath, array}
\usepackage{amsfonts}
\usepackage{comment}
\usepackage{fancyhdr}
\usepackage{mathrsfs}
\usepackage{enumitem}
\usepackage{bm}


\usepackage{tikz}

\voffset = -50pt
%\textheight = 700pt
\addtolength{\textwidth}{60pt}
\addtolength{\evensidemargin}{-30pt}
\addtolength{\oddsidemargin}{-30pt}
%\setlength{\headheight}{44pt}

\pagestyle{fancy}
\fancyhf{} % clear all fields
\fancyhead[R]{%
  \scshape
  \begin{tabular}[t]{@{}r@{}}
  MATH 590, Fall 2015\\Section 1 (9529)\\
  HW \#02, DUE: 2015, September 09
  \end{tabular}}
\fancyhead[L]{%
  \scshape
  \begin{tabular}[t]{@{}r@{}}
  JOSEPH OKONOBOH\\Mathematics\\Cal State Long Beach
  \end{tabular}}
\fancyfoot[C]{\thepage}

\newcommand{\qed}{\hfill \ensuremath{\Box}}

\newcommand{\col}[2]{\left(\begin{tabular}{@{}c@{}}
   $#1$ \\
   $#2$  
 \end{tabular}\right)}

\newcommand*\circled[1]{\tikz[baseline=(char.base)]{
            \node[shape=circle,draw,inner sep=2pt] (char) {#1};}}

\newcommand{\Z}{\mathbb{Z}}
\newcommand{\I}{\mathbb{I}}
\newcommand{\F}{\mathbb{F}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\renewcommand{\S}{\mathbb{S}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\D}{\displaystyle}
%\setcounter{section}{-1}

\begin{document}
\begin{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%01%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item Consider the veracity or falsehood of each of the following statements.
         For bonus, argue for those that you believe are true while providing a
         counterexample for those that you believe are false. Here $A$ and $B$
         are adjacency matrices of graphs.

         \begin{enumerate}[label=\protect\circled{\arabic*}]
            \item $AB$ is a symmetric matrix.
            \item $A$ is regular if and only if $AJ = kJ$ for some constant $k$.
            \item $A^2 + I$ is invertible.
            \item $AJ = JA$ implies $A$ is regular.
            \item If $A$ is connected and $AJ = 3J$, then 3 only occurs once as
                  an eigenvalue of $A$.
         \end{enumerate}
         
      \textbf{Solution.}

      \begin{enumerate}[label=\protect\circled{\arabic*}]
         \item False.
         
               \textbf{Counterexample.} Let
               $$A = \left(\begin{tabular}{@{}ccc@{}}
                  0 & 0 & 1 \\
                  1 & 0 & 0 \\
                  0 & 0 & 0
               \end{tabular}\right) \text{ and }
               B = \left(\begin{tabular}{@{}ccc@{}}
                  0 & 1 & 1 \\
                  1 & 0 & 1 \\
                  1 & 1 & 0
               \end{tabular}\right).$$
               It follows that $AB = \left(\begin{tabular}{@{}ccc@{}}
                  1 & 0 & 1 \\
                  0 & 1 & 1 \\
                  0 & 0 & 0
               \end{tabular}\right)$, a non-symmetric matrix.
         \item True.

               $(\Rightarrow)$ Suppose $A$ is regular. Then it follows by 
               definition that every vertex in the graph that $A$ represents has 
               the same degree; that is, there exists a nonnegative integer $k$  
               such that the number of 1s in every row of $A$ is $k$. Thus
               $AJ = kJ$.

               $(\Leftarrow)$ Conversely suppose that $AJ = kJ$ for nonnegative
               integer $k$. Notice that the $(i,j)$ entry in the product $AJ$ is 
               the sum of the entries of row $i$. Since $AJ = kJ$, it follows
               that every $(i, j)$ entry is $k$, so that the sum of every row is
               $k$. Thus the number of 1s in every row of $A$ must be the same,
               so that $A$ is regular. Thus we conclude that $A$ is regular if 
               and only if $AJ = kJ$ for some constant $k$. \qed
         \item True.
         
               \textbf{Proof.} Let $x$ be an eigenvalue of $A$. Since $A$ is
               symmetric, we know from Linear Algebra that $x$ must be a real
               number. Now since the spectrum of a polynomial is the polynomial
               of the spectrum, it follows that $x^2 + 1$ must be an eigenvalue
               of $A^2 + I$. But since $x$ is real, the number $x^2 + 1$ can
               never be 0. Thus $A^2 + I$ has no zero eigenvalues; that is,
               $A^2 + I$ has a nonzero determinant, so that it is invertible.
               \mbox{ } \qed
         \item True.

               \textbf{Proof.} Suppose that $AJ = JA$. We previously noted that
               the $(i, j)$ entry of the product $AJ$ is the sum of the entries
               of row $i$, while the $(i, j)$ entry of the product $JA$ is the 
               sum of the entries of column $j$. Since $AJ = JA$, it follows
               that the sum of the entries in each row and each column must all
               be equal. Particularly, the sum of the entries in each row must
               be equal, so that the number of 1s in each row of $A$ is the
               same. Hence, we conclude that $A$ is regular. \qed
      \end{enumerate}
      
      
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%02%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item \textbf{On Graphs \& Their Automorphisms.} Let $G = (V, E)$ be a graph.
         Thus $V$ is the (finite) set of vertices and $E$ is the set of edges,
         and we are assuming the relation is symmetric and irreflexive: if
         $x \sim y$ then $y \sim x$, and $x \not\sim x$. A permutation or
         bijection $\alpha : V \rightarrow V$ is said to be an automorphism of
         $G$ if whenever $x \sim y$ then $\alpha(x) \sim \alpha(y)$. Let
         Aut($G$) denote the set of automorphisms.

         \begin{enumerate}[label=\protect\circled{\arabic*}]
            \item Prove Aut($G$) is a subgroup of the group of permutations of
                  $V$.
            \item Show that for any two vertices, $x, y \in V$, if there exists
                  $\alpha \in \text{Aut}(G)$ such that $\alpha(x) = y$, then
                  they have the same degree---namely the number of edges coming
                  out of each is the same.
         \end{enumerate}
         
      \textbf{Proof.}

      \begin{enumerate}[label=\protect\circled{\arabic*}]
         \item The set $\text{Aut}(G)$ is not empty since it contains the
               identity permutation---the permutation that fixes all vertices of
               $V$. Associativity is already taken care of because the group of
               permutations is associative under function composition; the
               identity permutation serves as the identity for Aut($G$), and
               since Aut($G$) is finite, it is also closed under taking
               inverses. So we only need to show closure under function
               composition. To that end, let
               $\beta, \gamma \in \text{Aut}(G)$. Suppose we have $x \sim y$ for
               some $x, y \in V$. Since $\gamma$ is a member of Aut($G$), it
               follows that $\gamma(x) \sim \gamma(y)$. Similarly, since
               $\gamma(x)$ and $\gamma(y)$ are members of $V$, it follows that
               $\beta(\gamma(x)) \sim \beta(\gamma(y))$, so that
               $(\beta\circ\gamma)(x) \sim (\beta\circ\gamma)(y)$; that is,
               $\beta\circ\gamma \in \text{Aut}(G)$, and so we conclude that
               $\text{Aut}(G) \le S_V$.
         \item Let $S_v = \{u \in V: u \sim v\}$, where $v \in V$. It is clear
               that for $v \in V$, we have $\text{degree($v$)} = |S_v|$. Now
               suppose that there exist $x, y \in V$ and
               $\alpha \in \text{Aut}(G)$ such that $\alpha(x) = y$. We want to
               show that degree($x$) = degree($y$); that is, $|S_x| = |S_y|$.
               Assume that $S_x$ is not empty. So let
               $a \in S_x$, so that $x \sim a$. It follows that
               $y = \alpha(x) \sim \alpha(a)$; that is, $\alpha(a) \in S_y$.
               Since $\alpha$ is injective, it must therefore map all elements
               of $S_x$ to unique elements in $S_y$; thus $|S_x| \le |S_y|$.
               Now let $b \in S_y$, so that $y \sim b$; recall that Aut($G$) is
               a group, so we must have $\alpha^{-1} \in \text{Aut}(G)$. Thus
               since $y \sim b$, it follows that
               $x = \alpha^{-1}(y) \sim \alpha^{-1}(b)$, so that
               $\alpha^{-1}(b) \in S_x$. Similarly, we conclude that
               $\alpha^{-1}$ maps elements of $S_y$ to unique elements in $S_x$
               because it is injective. Thus $|S_y| \le |S_x|$ and we conclude
               that $|S_x| = |S_y|$, so that degree($x$) = degree($y$). Now if
               $S_x$ is empty, then our arguments above show us that $S_y$ must
               also be empty (since the preimage of the elements of $S_y$ under
               $\alpha$ are precisely the elements of $S_x$), and the proof is
               complete.\qed
      \end{enumerate}
      
      
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%03%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item We are going to describe a graph with 50 vertices. The vertices $V$ are
         simply the following $(a \quad b)$ and $\col{a}{b}$ where
         $a, b \in \Z_5$. Recall that the squares $\S$ in $\Z_5$ are $\{1, 4\}$
         and the non-squares $\N$ are $\{2, 3\}$. Observe $-\S = \S$ and
         $-\N = \N$. We now describe the edges:

         $(a \quad b) \sim (c \quad d)$ if and only if $a = c$ and
         $b - d \in \S$. Note this is symmetric. $\col{a}{b} \sim \col{c}{d}$
         if and only if $a = c$ and $b - d \in \N$. Note this is symmetric.
         $(a \quad b) \sim \col{c}{d}$ if and only if
         $\col{c}{d} \sim (a \quad b)$ if and only if $b = ca + d$. Since
         $0 \notin \S \cup \N$, the relation is irreflexive so we have a
         graph $G$. Let $A$ be its $50 \times 50$ adjacency matrix. Do the
         following:

         \begin{enumerate}[start=0, label=\protect\circled{\arabic*}]
            \item Find the vertices connected to $(0 \quad 0)$.
                  \textbf{Hint.} Do it by cases.
            \item Find the vertices connected to $\col{0}{0}$.
            \item Show the mapping $\alpha_x : V \rightarrow V$ defined by
                  $(a \quad b) \mapsto (a \quad b + x)$ and
                  ${\col{c}{d} \mapsto \col{c}{d+x}}$ is an automorphism of the
                  graph.
            \item Let $m \neq 0 \in \Z_5$. Show that the mapping
                  $$\beta_m(a \quad b) = (ma \quad b) \text{ and }
                    \beta_m\left(\col{c}{d}\right) = \col{m^{-1}c}{d}$$
                  is an automorphism of the graph.
            \item Show that $AJ = kJ$ for some $k$ and find the $k$.
            \item Show that if $(a \quad b) \sim (c \quad d)$, or
                  $\col{a}{b} \sim \col{c}{d}$, or
                  $(a \quad b) \sim \col{c}{d}$, then there is no vertex joined
                  to both. \textbf{Hint.} Do cases.
            \item Show that if $(a \quad b) \not\sim (c \quad d)$, or
                  $\col{a}{b} \not\sim \col{c}{d}$, or
                  $(a \quad b) \not\sim\col{c}{d}$, then there is exactly one
                  vertex joined to both.
            \item Show there exist integers $m, n, l$ such that   
                  $A^2 = mA + nI + lJ$ and find them.
            \item Find the spectrum of the graph. \textbf{Hint.} Use the
                  spectrum of $J$ and the fact that the spectrum of a polynomial
                  is the polynomial of the spectrum, and use the trace.
         \end{enumerate}
         
      \textbf{Solution.}

      \begin{enumerate}[start=0, label=\protect\circled{\arabic*}]
         \item Suppose that $(0 \quad 0) \sim (a \quad b)$ and
               $(0 \quad 0)\sim \col{c}{d}$. It follows that $a = 0$ and
               $b - 0 = b \in \S$ and $0 = 0 + d$. Thus the vertices
               connected to $(0 \quad 0)$ are:
               $$(0 \quad 1), (0 \quad 4), \col{0}{0}, \col{1}{0}, \col{2}{0},
               \col{3}{0}, \text{ and }\col{4}{0}.$$
         \item Now suppose that $\col{0}{0} \sim (a \quad b)$ and 
               $\col{0}{0} \sim \col{c}{d}$. Then it follows that
               $b = 0 \cdot a + 0 = 0$, $c = 0$, and $d - 0 = d \in \N$. Thus
               the vertices connected to $(0 \quad 0)$ are:
               $$(0 \quad 0), (1 \quad 0), (2 \quad 0), (3 \quad 0),
                 (4 \quad 0), \col{0}{2}, \text{ and } \col{0}{3}.$$
         \item Let $x \in V$. Consider the map
               $$\alpha_x : V \rightarrow V \text{ defined by } (a \quad b)
                 \mapsto (a \quad b + x) \text{ and } {\col{c}{d}
                 \mapsto \col{c}{d+x}}.$$
               Since the map $\alpha_{-x}$ is a two sided inverse of $\alpha_x$,
               it follows that $\alpha_x$ is bijective and thus a permutation of
               $V$. Now we shall show that $\alpha_x$ is an automorphism for all
               possible cases:
               
               \textbf{Case 1.} $(a \quad b) \sim (c \quad d)$; that is, $a = c$
               and $b - d \in \S$. It follows that
               \begin{align*}
                  \alpha_x((a \quad b)) &= (a \quad b+x) \\
                                        &= (c \quad b+x) &[\text{Since }a = c]\\
                                        &\sim (c \quad d+x) &[b+x -
                                         (d+x)=b-d \in \S]\\ 
                                        &= \alpha_x((c \quad d)),
               \end{align*}
               so that $ \alpha_x((a \quad b)) \sim  \alpha_x((c \quad d))$.
               
               \textbf{Case 2.} $\col{a}{b} \sim \col{c}{d}$. The proof is
               similar to Case I (however, replace $\S$ with $\N$).
               
               \textbf{Case 3.} $(a \quad b) \sim \col{c}{d}$. That is,
               $b = ca + d$, so that $b + x = ca + d + x$. Hence
               \begin{align*}
                  \alpha_x((a \quad b)) = (a \quad b+x)
                                        &\sim \col{c}{d+x} &[b + x = ca + d+x]\\ 
                                        &= \alpha_x\left(\col{c}{d}\right),
               \end{align*}
               so that $ \alpha_x((a \quad b)) \sim 
               \alpha_x\left(\col{c}{d}\right)$.
         \item Let $m$ be a nonzero element in $\Z_5$, so that $m^{-1}$ exists.
               Consider the map
               $$\beta_m : V \rightarrow V \text{ defined by } (a \quad b)
                 \mapsto (ma \quad b) \text{ and }
                 \beta_m\left(\col{c}{d}\right) = \col{m^{-1}c}{d}.$$
               The map $\beta_m$ is a permuation of $V$ because it has a
               two-sided inverse, namely $\beta_{m^{-1}}$. Now we shall show
               that $\alpha_x$ is an automorphism for all possible cases:
               
               \textbf{Case 1.} $(a \quad b) \sim (c \quad d)$; that is, $a = c$
               and $b - d \in \S$. It follows that
               \begin{align*}
                  \beta_m((a \quad b)) &= (ma \quad b) \\
                                       &= (mc \quad b) &[\text{Since }a = c] \\
                                       &\sim (mc \quad d) &[b - d \in \S]\\ 
                                        &= \alpha_x((c \quad d)),
               \end{align*}
               so that $ \beta_m((a \quad b)) \sim  \beta_m((c \quad d))$.
               
               \textbf{Case 2.} $\col{a}{b} \sim \col{c}{d}$. The proof is
               similar to Case I (however, replace $\S$ with $\N$).
               
               \textbf{Case 3.} $(a \quad b) \sim \col{c}{d}$. That is,
               $b = ca + d$, so that
               $$b = cm^{-1}ma + d = (m^{-1}c)(ma) + d.$$
               Hence
               \begin{align*}
                  \beta_m((a \quad b)) = (ma \quad b)
                                        &\sim \col{m^{-1}c}{d}
                                          &[b = (m^{-1}c)(ma) + d] \\ 
                                        &= \alpha_x\left(\col{c}{d}\right),
               \end{align*}
               so that $ \beta_m((a \quad b)) \sim 
               \beta_m\left(\col{c}{d}\right)$.
         \item Consider the arbitrary vertices $(a \quad b)$ and $\col{c}{d}$.
               A few compuations will reveal that the vertices $(a \quad b)$ is
               connected to are:
               $$(a \quad b+1), (a \quad b+4), \col{0}{b}, \col{1}{b-a},
                 \col{2}{b-2a}, \col{3}{b-3a}, \text{ and }\col{4}{b-4a},$$
               and the vertices $\col{c}{d}$ is connected to are:
               $$(0 \quad d), (1 \quad c+d), (2 \quad 2c+d), (3 \quad 3c+d),
                 (4 \quad 4c+d), \col{c}{2+d}, \text{ and } \col{c}{3+d}.$$
               That is, every vertex in $V$ is connected to exactly seven
               other vertices, so that $AJ = 7J$.
         \item \textbf{Proof.} Suppose two vertices $v_1, v_2 \in V$ are joined.

               \textbf{Case 1.} $v_1 = (a \quad b)$ and $v_2 = (c \quad d)$.
               
               \begin{quote}
                  \textbf{Case (a).} $v_1 \sim (p \quad q)$ and
                  $v_2 \sim (p \quad q)$. Since $v_1$ is joined to both $v_2$
                  and $(p \quad q)$, we can use our results in \circled{4} to 
                  assume without loss of generality that $v_2$ is
                  $(a \quad b+1)$ while $(p \quad q)$ is $(a \quad b+4)$. But
                  $b+4-(b+1) = 3 \notin \S$. That is, $(p \quad q)$ is not 
                  joined to $v_2$, a contradiction. So no other vertex of the 
                  form $(p \quad q)$ is joined to $v_1$ and $v_2$.
               \end{quote}

               \begin{quote}
                  \textbf{Case (b).} $v_1 \sim \col{p}{q}$ and
                  $v_2 \sim \col{p}{q}$. The former relation allows us to 
                  conclude that $b = ap+q$. Since $v_2 \sim v_1$, we know that
                  $v_2 = (a \quad b + 1)$ or $v_2 = (a \quad b + 4)$. The former
                  case will imply that $b = (ap + q) - 1$ and the latter case 
                  will imply that $b = (ap + q) - 4$, both contradicting our 
                  previous result that says that $b = ap + q$. Thus, we have 
                  shown that $v_1$ and $v_2$ are not both joined to any other 
                  vertex.
               \end{quote}

               \textbf{Case 2.} $v_1 = (a \quad b)$ and $v_2 = \col{c}{d}$.
               
               \begin{quote}
                  \textbf{Case (a).} $v_1 \sim (p \quad q)$ and
                  $v_2 \sim (p \quad q)$. By Case 1(a), this is impossible.
               \end{quote}
   
               \begin{quote}
                  \textbf{Case (b).} $v_1 \sim \col{p}{q}$ and
                  $v_2 \sim \col{p}{q}$. Since $v_2$ is joined to $\col{p}{q}$, 
                  it follows that $\col{p}{q} = \col{c}{2+d}$ or
                  $\col{p}{q} = \col{c}{3+d}$; since $\col{p}{q}$ is also joined 
                  to $v_1$, we must have that $b = ac + d + 2$ in the former 
                  case or $b = ac + d + 3$ in the latter case, contradicting the 
                  fact that $b = ac + d$ (since $v_1 \sim v_2$). Thus, we have 
                  shown that $v_1$ and $v_2$ are not both joined to any other 
                  vertex.
               \end{quote}

               \textbf{Case 3.} $v_1 = \col{a}{b}$ and $v_2 = \col{c}{d}$.
               
               \begin{quote}
                  \textbf{Case (a).} $v_1 \sim (p \quad q)$ and
                  $v_2 \sim (p \quad q)$. By Case 2(b), this is impossible.
               \end{quote}
   
               \begin{quote}
                  \textbf{Case (b).} $v_1 \sim \col{p}{q}$ and
                  $v_2 \sim \col{p}{q}$. Since $v_1 \sim (p \quad q)$, it
                  follows that $q = ap + b$; now we know that
                  $v_2 = \col{a}{b+2}$ or $v_2 = \col{a}{b+3}$ because
                  $v_2 \sim v_1$, and since $(p \quad q) \sim v_1$, we must
                  either have $q = ap + b + 2$ or $q = ap + b + 3$,
                  contradicting the fact that $q = ap + b$. Thus, we have shown
                  that $v_1$ and $v_2$ are not both joined to any other vertex.
               \end{quote} 

               From all the possible cases above, we conclude that no other 
               vertex is joined to both $v_1$ and $v_2$. \qed
         \item Let $v_1, v_2 \in V$ such that $v_1 \not\sim v_2$. We now want to
               find a unique vertex that joins both $v_1$ and $v_2$.

               \textbf{Case 1.} $v_1 = (a \quad b)$ and $v_2 = (c \quad d)$.
               
               \begin{quote}
                  \textbf{Case (a).} $a \neq c$. Thus a vertex of the form 
                  $(p \quad q)$ cannot be joined to both $v_1$ and $v_2$, for
                  otherwise, we would have $a = p = c$, contradicting
                  $a \neq c$. So assume that $\col{p}{q}$ is joined to both
                  $v_1$ and $v_2$. To show existence and uniqueness, it suffices
                  to show that $p$ and $q$ can each take on exactly one value.
                  Since $\col{p}{q}$ is joined to both $v_1$ and $v_2$, we have
                  the following equations:
                  \begin{equation} \label{2_6_1}
                     b = pa + q \text{ and } d = pc + q.
                  \end{equation}
                  Substituting $q = b - pa$ from the first equation into the 
                  second will yield $b - d = p(a - c)$. Since $a \neq c$, it
                  follows that $(a-c)^{-1}$ exists; that is,
                  $$p = (a-c)^{-1}(b - d) \text{ and } q=(da - bc)(a-c)^{-1},$$
                  so that only one vertex is joined to both $v_1$ and $v_2$.
               \end{quote}
               
               \begin{quote}
                  \textbf{Case (b).} $a = c$ and $b - d \notin \S$. Now a vertex 
                  of the form $\col{p}{q}$ cannot be joined to both $v_1$ and    
                  $v_2$, for otherwise, we would have from \eqref{2_6_1} that
                  $b = d$, a statement that is not generally true (take $a=c=1$,
                  $b = 4$, and $d = 2$). So assume that $(p \quad q)$ is joined 
                  to both $v_1$ and $v_2$. It immediately follows that
                  $c = p = a$. Also, we must have that $b - q \in \S$ and
                  $d - q \in \S$. Note that we cannot have $b - q = d - q$ since
                  that would imply that $b = d$. So suppose first that
                  $b - q = 1$ and $d - q = 4$. That is, $q = b - 1 = d - 4$,
                  so that $b - d = 2 \in \N$, in agreement with our hypothesis.
                  Now if $b - q = 4$ and $d - q = 1$, then we would have that
                  $q = b - 4 = d - 1$, so that $b - d = 3 \in \N$. That is,
                  only one vertex is joined to both $v_1$ and $v_2$.
               \end{quote}

               \textbf{Case 2.} $v_1 = (a \quad b)$ and $v_2 = \col{c}{d}$.
               Since $v_1$ is not joined to $v_2$, it follows that
               $b \neq ca + d$, so that $b - (ca + d) \neq 0$.
               
               \begin{quote}
                  \textbf{Case (a).} $b - (ca + d) \in \S$. Suppose first that
                  $b - (ca + d) = 1$, so that $b = ca + d + 1$. We shall now
                  show that a vertex of the form $\col{p}{q}$ cannot join both
                  $v_1$ and $v_2$. So suppose otherwise. Since
                  $v_2 \sim \col{p}{q}$, it follows that $p = c$ and
                  $d - q \in \N$, and $b = ap + q = ac + q$ since
                  $v_1 \sim \col{p}{q}$. Now since $b = ca + d + 1$ and
                  $b = ac + q$, it follows that $d + 1 = q$, so that
                  $d - q = 4 \notin \N$, a contradiction. So assume that
                  $(p \quad q)$ is joined to $v_1$ and $v_2$. We must have that
                  $p = a$ and $b - q \in \S$ since $v_1 \sim (p \quad q)$.
                  Similarly, it follows that $q = pc + d = ac + d$ because
                  $v_2 \sim (p \quad q)$. But recall that $b = ca + d + 1$; so
                  we conclude that $b - q = 1 \in \S$. So choose $q = b - 1$. 
                  Now if $b - (ca + d) = 4$, repeat the process above. That is,
                  first show that $\col{r}{s}$ cannot join both $v_1$ and $v_2$.
                  Then show that $(r \quad s)$, where $r = a$ and $s = b - 4$ is
                  the only vertex that joins $v_1$ and $v_2$.
               \end{quote}
               
               \begin{quote}
                  \textbf{Case (b).} $b - (ca + d) \in \N$. Suppose first that
                  $b - (ca + d) = 2$, so that $b = ca + d + 2$. We shall now
                  show that a vertex of the form $(p \quad q)$ cannot join both
                  $v_1$ and $v_2$. So suppose otherwise. Since
                  $v_1 \sim (p \quad q)$, it follows that $p = a$ and
                  $b - q \in \S$, and $q = cp + d = ca + d$ since
                  $v_2 \sim (p \quad q)$. Now since $b = ca + d + 2$ and
                  $q = ca + d$, it follows that $b - q = 2 \notin \S$, a 
                  contradiction. So assume that $\col{p}{q}$ is joined to
                  $v_1$ and $v_2$. We must have that $p = c$ and $d - q \in \N$ 
                  since $v_2 \sim \col{p}{q}$. Similarly, it follows that
                  $b = pa + q = ca + q$ because $v_1 \sim \col{p}{q}$. But 
                  recall that $b = ca + d + 2$; so we conclude that
                  $d - q = 2 \in \N$. So choose $q = d - 2$. Now if
                  $b - (ca + d) = 3$, repeat the process above. That is,
                  first show that $(r \quad s)$ cannot join both $v_1$ and
                  $v_2$. Then show that $\col{r}{s}$, where $r = c$ and
                  $s = d - 3$ is the only vertex that joins $v_1$ and $v_2$.
               \end{quote}

               \textbf{Case 3.} $v_1 = \col{a}{b}$ and $v_2 = \col{c}{d}$.
               
               \begin{quote}
                  \textbf{Case (a).} $a \neq c$. The argument for this case is
                  similar to that for Case 1(a). However, in this case, the
                  unique vertex that joins $v_1$ and $v_2$ is of the form $(p 
                  \quad q)$, where, as in Case 1(a),
                  $$p = (a-c)^{-1}(b - d) \text{ and } q=(da - bc)(a-c)^{-1}.$$
               \end{quote}
               
               \begin{quote}
                  \textbf{Case (b).} $a = c$ and $b - d \notin \N$. Now a vertex 
                  of the form $(p \quad q)$ cannot be joined to both $v_1$ and
                  $v_2$, for otherwise, we would have that $q = pa + b = pc + b$
                  and $q = pc + d$, so that $b = d$, a contradiction if we
                  take $a=c=1$, $b = 4$, and $d = 0$. So assume that
                  $\col{p}{q}$ is joined to both $v_1$ and $v_2$. It immediately 
                  follows that $c = p = a$. Also, we must have that
                  $b - q \in \N$ and $d - q \in \N$. Note that we cannot have
                  $b - q = d - q$ since that would imply that $b = d$. So 
                  suppose first that $b - q = 2$ and $d - q = 3$. That is,
                  $q = b - 2 = d - 3$, so that $b - d = 4 \notin \N$, in 
                  agreement with our hypothesis. Now if $b - q = 3$ and
                  $d - q = 2$, then we would have that $q = b - 3 = d - 2$, so 
                  that $b - d = 1 \notin \N$. That is, only one vertex is joined 
                  to both $v_1$ and $v_2$.
               \end{quote}
         \item Recall that the $(i, j)$ entry of $A^n$ is the number of paths of
               length $n$ from vertex $i$ to vertex $j$. Suppose there is a
               path of length two from a vertex to itself, say
               $k \rightarrow l \rightarrow k$. Then it follows that vertex $k$
               must be joined to vertex $l$. The converse is also true. Thus the
               main diagonal of $A^2$ must all be 7s because each vertex is
               joined to exactly seven other vertices. We showed in \circled{5}
               that if vertex $i$ is joined to vertex $j$, then no other vertex
               joins the both of them; that is, there is no path of length two
               from $i$ to $j$. So the non-diagonal entries of $A$ that contain
               1s must contain 0s in $A^2$. Now if $i$ and $j$ are not
               connected, then, according to \circled{6}, there is exactly 1  
               vertex joining the both of them. So the non-diagonal entries of
               $A$ that contain 0s must contain 1s in $A^2$. It follows that
               $$A^2 = -A + 6I + J.$$
         \item The spectrum of $J_{50}$ is
               $50, \underbrace{0, \cdots, 0}_{49 \text{ times}}$. Since
               $A^2 + A = 6I + J_{50}$, it follows that the spectrum of
               $A^2 + A$ is $56, \underbrace{6, \cdots, 6}_{49 \text{ times}}$.
               That is, one of the eigenvalue of $A$ must satisfy
               $\mu^2+\mu=56$. We know that $AJ = 7J$, so this eigenvalue must 
               be 7. The other eigenvalues must satisfy $\lambda^2+\lambda = 6$; 
               thus $\lambda = -3$ or $\lambda = 2$. Let $m$ and $n$ be the
               multiplicities of $-3$ and $2$ respectively. It follows that
               $$m + n = 49 \text{ and } 7 - 3m + 2n = 0.$$
               Solving these equations will yield $m = 21$ and $n = 28$. Thus
               the spectrum of $A$ is
               $$7, \underbrace{-3, \cdots, -3}_{21 \text{ times}},
                    \underbrace{2, \cdots, 2}_{28 \text{ times}}$$
      \end{enumerate}   
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Bonus%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
   \item[\textbf{Bonus.}]  Let $G$ be a connected graph. If for any two vertices
                           $x, y \in V$, there exists $\alpha \in \text{Aut}(G)$
                           such that $\alpha(x) = y$, then we say the group of
                           automorphisms is \textbf{vertex transitive}.

                           \begin{enumerate}[label=\protect\circled{\arabic*}]   
                              \item Prove that if $\text{Aut}(G)$ is vertex
                                    transitive, then the graph is regular,
                                    namely the number of edges leaving a vertex
                                    is the same for any two vertices. Assume
                                    vertex transitivity. Then $\text{Aut}(G)$ is
                                    \textbf{edge transitive} when for any pairs
                                    of points, $x_1 \sim y_1$ and $x_2 \sim y_2$
                                    there exists $\alpha \in \text{Aut}(G)$ such
                                    that $\alpha(x_1) = x_2$ and
                                    $\alpha(x_2) = y_2$.
                              \item Prove that if $\text{Aut}(G)$ is
                                    \textbf{edge transitive}, and if
                                    $x_1 \not\sim y_1$ and $x_2 \not\sim y_2$,
                                    there exists $\alpha \in \text{Aut}(G)$ such
                                    that $\alpha(x_1) = x_2$ and
                                    $\alpha(x_2) = y_2$.
                              \item Prove that if $\text{Aut}(G)$ is edge
                                    transitive, and $A$ is the adjacency matrix
                                    of the graph, then there exist integers
                                    $a, b, c$ such that $A^2 = aA + bI +cJ$.
                              \item Decide if the graph in the previous problem
                                    has a vertex transitive group or an edge
                                    transitive group.
                           \end{enumerate}

      \textbf{Solution.}

      \begin{enumerate}[label=\protect\circled{\arabic*}]
         \item 
      \end{enumerate}
\end{enumerate}
\end{document}
